{"cells":[{"cell_type":"markdown","id":"0d9b1ccb-1e17-4325-a1eb-bbf9d9b8879a","metadata":{},"outputs":[],"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","id":"3fd50f2e-3f4a-4f32-b732-a1961f756561","metadata":{},"outputs":[],"source":["# **Finding Duplicates Lab**\n"]},{"cell_type":"markdown","id":"860df127-9e5f-4b29-846e-8ba12d536784","metadata":{},"outputs":[],"source":["Estimated time needed: **30** minutes\n"]},{"cell_type":"markdown","id":"c1784873-6ea2-46de-aab6-34c3c6fee8d6","metadata":{},"outputs":[],"source":["## Introduction\n"]},{"cell_type":"markdown","id":"1857c3f1-c604-4d6b-b551-19f4f356ee7e","metadata":{},"outputs":[],"source":["Data wrangling is a critical step in preparing datasets for analysis, and handling duplicates plays a key role in ensuring data accuracy. In this lab, you will focus on identifying and removing duplicate entries from your dataset. \n"]},{"cell_type":"markdown","id":"442ed7e0-619e-4a5c-8fab-7b74be9dda81","metadata":{},"outputs":[],"source":["## Objectives\n"]},{"cell_type":"markdown","id":"4d6fa756-8965-4cbf-a568-ad98362ae921","metadata":{},"outputs":[],"source":["In this lab, you will perform the following:\n"]},{"cell_type":"markdown","id":"096b7a9a-5368-49f8-b2d2-8329f5e14fc0","metadata":{},"outputs":[],"source":["1. Identify duplicate rows in the dataset and analyze their characteristics.\n","2. Visualize the distribution of duplicates based on key attributes.\n","3. Remove duplicate values strategically based on specific criteria.\n","4. Outline the process of verifying and documenting duplicate removal.\n"]},{"cell_type":"markdown","id":"d8329849-34c2-4d9e-9567-15370e8fef6c","metadata":{},"outputs":[],"source":["## Hands on Lab\n"]},{"cell_type":"markdown","id":"a8e7bdf8-2e11-44f5-b6e3-e9c2e7ad766c","metadata":{},"outputs":[],"source":["Install the needed library\n"]},{"cell_type":"code","id":"2e9dc645-7958-4d22-a004-b18d62a6efc9","metadata":{},"outputs":[],"source":["!pip install pandas\n!pip install matplotlib"]},{"cell_type":"markdown","id":"d850c702-b3c6-472e-97e6-784dfc4d7657","metadata":{},"outputs":[],"source":["Import pandas module\n"]},{"cell_type":"code","id":"9b01f14b-8e35-4d16-8ca5-78088b3dc7db","metadata":{},"outputs":[],"source":["import pandas as pd\n"]},{"cell_type":"markdown","id":"5e0b5037-750e-4f9c-a3c8-be19a0f0fb7f","metadata":{},"outputs":[],"source":["Import matplotlib\n"]},{"cell_type":"code","id":"b6be1eb5-be4d-4a83-a184-979457428725","metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n"]},{"cell_type":"markdown","id":"6a2e8452-3c54-43e4-a568-19916e762331","metadata":{},"outputs":[],"source":["## **Load the dataset into a dataframe**\n"]},{"cell_type":"markdown","id":"ef0de7ff-2a28-43df-b9f0-a3329da2b27e","metadata":{},"outputs":[],"source":["<h2>Read Data</h2>\n","<p>\n","We utilize the <code>pandas.read_csv()</code> function for reading CSV files. However, in this version of the lab, which operates on JupyterLite, the dataset needs to be downloaded to the interface using the provided code below.\n","</p>\n"]},{"cell_type":"code","id":"da2146c8-bbb3-4b87-ac0a-e15d099c688e","metadata":{},"outputs":[],"source":["# Load the dataset directly from the URL\nfile_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/VYPrOu0Vs3I0hKLLjiPGrA/survey-data-with-duplicate.csv\"\ndf = pd.read_csv(file_path)\n\n# Display the first few rows\nprint(df.head())"]},{"cell_type":"markdown","id":"873cfff6-094b-4d40-9eae-99d13b91a16f","metadata":{},"outputs":[],"source":["Load the data into a pandas dataframe:\n","\n"]},{"cell_type":"markdown","id":"d8c5c700-c03b-4417-b075-c2b8e1f468ea","metadata":{},"outputs":[],"source":["Note: If you are working on a local Jupyter environment, you can use the URL directly in the pandas.read_csv() function as shown below:\n","\n"]},{"cell_type":"code","id":"e1f2347e-fa12-425b-a7c7-52462add160c","metadata":{},"outputs":[],"source":["# df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\")\n"]},{"cell_type":"markdown","id":"039095a6-af41-42a5-bc15-1f5715b30ad6","metadata":{},"outputs":[],"source":["## Identify and Analyze Duplicates\n"]},{"cell_type":"markdown","id":"d09621e9-02ae-46b9-88dd-0b8a96b1336b","metadata":{},"outputs":[],"source":["### Task 1: Identify Duplicate Rows\n","1. Count the number of duplicate rows in the dataset.\n","3. Display the first few duplicate rows to understand their structure.\n"]},{"cell_type":"code","id":"4b0a5f12-97d0-4c18-a1a4-dce70f8418df","metadata":{},"outputs":[],"source":["## Write your code here"]},{"cell_type":"markdown","id":"655d4b89-d51b-4889-bf2f-38fcb0a7b926","metadata":{},"outputs":[],"source":["### Task 2: Analyze Characteristics of Duplicates\n","1. Identify duplicate rows based on selected columns such as MainBranch, Employment, and RemoteWork. Analyse which columns frequently contain identical values within these duplicate rows.\n","2. Analyse the characteristics of rows that are duplicates based on a subset of columns, such as MainBranch, Employment, and RemoteWork. Determine which columns frequently have identical values across these rows.\n","   \n"]},{"cell_type":"code","id":"8b9928b3-ee07-45a2-8f88-cf339457c7db","metadata":{},"outputs":[],"source":["## Write your code here"]},{"cell_type":"markdown","id":"b805a48c-e8b3-42e3-8e67-8de52afc3f09","metadata":{},"outputs":[],"source":["### Task 3: Visualize Duplicates Distribution\n","1. Create visualizations to show the distribution of duplicates across different categories.\n","2. Use bar charts or pie charts to represent the distribution of duplicates by Country and Employment.\n"]},{"cell_type":"code","id":"9d5016a8-583b-4db1-adb9-681b72aeba55","metadata":{},"outputs":[],"source":["## Write your code here"]},{"cell_type":"markdown","id":"87211b7d-14f3-41b8-a883-9f77d25f55c1","metadata":{},"outputs":[],"source":["### Task 4: Strategic Removal of Duplicates\n","1. Decide which columns are critical for defining uniqueness in the dataset.\n","2. Remove duplicates based on a subset of columns if complete row duplication is not a good criterion.\n"]},{"cell_type":"code","id":"7e1c64b7-5b48-4837-b139-1bc410faa0bc","metadata":{},"outputs":[],"source":["## Write your code here"]},{"cell_type":"markdown","id":"b1e36e50-897e-49ad-bbce-c788043a4424","metadata":{},"outputs":[],"source":["## Verify and Document Duplicate Removal Process\n"]},{"cell_type":"markdown","id":"64e47f9d-977b-420c-8c13-c050ea305392","metadata":{},"outputs":[],"source":["### Task 5: Documentation\n","1. Document the process of identifying and removing duplicates.\n"]},{"cell_type":"raw","id":"96ac861d-f2ff-41bc-83ee-441a92281ba6","metadata":{},"outputs":[],"source":["# Write your explanation here"]},{"cell_type":"markdown","id":"0e1fbbaa-0de2-492a-91d8-85111ef48c8b","metadata":{},"outputs":[],"source":["2. Explain the reasoning behind selecting specific columns for identifying and removing duplicates.\n"]},{"cell_type":"raw","id":"5892c110-4910-4875-93dc-4463d69692ca","metadata":{},"outputs":[],"source":["# Write your explanation here"]},{"cell_type":"markdown","id":"a1c7e20a-1bf6-4527-8e96-72327c45cd80","metadata":{},"outputs":[],"source":["### Summary and Next Steps\n","**In this lab, you focused on identifying and analyzing duplicate rows within the dataset.**\n","\n","- You employed various techniques to explore the nature of duplicates and applied strategic methods for their removal.\n","- For additional analysis, consider investigating the impact of duplicates on specific analyses and how their removal affects the results.\n","- This version of the lab is more focused on duplicate analysis and handling, providing a structured approach to deal with duplicates in a dataset effectively.\n"]},{"cell_type":"markdown","id":"a5cf91f9-2dda-45b4-9fdd-0bc91a1484d3","metadata":{},"outputs":[],"source":["<!--\n","## Change Log\n","|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n","|-|-|-|-|\n","|2024-11- 05|1.3|Madhusudhan Moole|Updated lab|\n","|2024-10-28|1.2|Madhusudhan Moole|Updated lab|\n","|2024-09-24|1.1|Madhusudhan Moole|Updated lab|\n","|2024-09-23|1.0|Raghul Ramesh|Created lab|\n","--!>\n"]},{"cell_type":"markdown","id":"066efe23-175b-4c0f-8abc-379169aec311","metadata":{},"outputs":[],"source":["Copyright Â© IBM Corporation. All rights reserved.\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"prev_pub_hash":"fa3493caccf457f2b33a3a72ca6bf5789c2ce4157ea6e40534b09cc8380e8ae5"},"nbformat":4,"nbformat_minor":4}